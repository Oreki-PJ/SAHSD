task_name: t4sa_hatexplainthr
train_path: data/hatexplain/thr_div/n_sample/
dev_path: data/hatexplain/thr_div/val_data.csv
test_path: data/hatexplain/thr_div/test_data.csv
task_type: binary

# Pretrained model path or name
trained_model: output/T4SA_pp50_bert_base/

# Output
# output_dir: output/T4SA_sampled_bert_base/
# log_file: SBIC.log
# pred_file: SBIC.npy  # save predicted label ids

# Prompt
pet_method: skip_first  # skip_first, skip_second
full_vocab_loss: yes
# encoder_type: none  # emb, mlp, lstm, none

# Train & evaluation
use_gpu: yes
max_seq_len: 512
# seed: 3407  # random seed for training
shuffle: yes  # whether shuffle order of training samples
train_batch_size: 16
grad_acc_steps: 1
eval_every_steps: 20  # evaluation after weight update steps
test_batch_size: 32
warmup_ratio: 0.05
weight_decay: 0.01
learning_rate: 2.0e-5
adam_epsilon: 1.0e-8
max_grad_norm: 1.0
max_train_epochs: 20
early_stop_steps: 5
save_metric: 'f1_score'
